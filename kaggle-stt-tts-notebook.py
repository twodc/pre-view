# =============================================================================
# Pre-View STT + TTS Service (Kaggle Notebook)
# VibeVoice-ASR + Qwen3-TTS
# =============================================================================

# %% [markdown]
# # Pre-View ìŒì„± ì„œë¹„ìŠ¤
# - **STT**: Microsoft VibeVoice-ASR (ìŒì„± â†’ í…ìŠ¤íŠ¸)
# - **TTS**: Qwen3-TTS (í…ìŠ¤íŠ¸ â†’ ìŒì„±)

# %% Cell 1: ì˜ì¡´ì„± ì„¤ì¹˜
!pip install -q gradio transformers accelerate torch soundfile scipy
!pip install -q qwen-tts bitsandbytes  # Qwen3-TTS + ì–‘ìí™”

# %% Cell 2: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import torch
import gradio as gr
import soundfile as sf
import tempfile
import numpy as np
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline, BitsAndBytesConfig

print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

# %% Cell 3: STT ëª¨ë¸ ë¡œë“œ (VibeVoice-ASR with INT8 ì–‘ìí™”)
print("Loading VibeVoice-ASR model...")

# ì–‘ìí™” ì„¤ì • (ë©”ëª¨ë¦¬ ì ˆì•½)
quantization_config = BitsAndBytesConfig(
    load_in_8bit=True,  # INT8 ì–‘ìí™”
)

try:
    # VibeVoice-ASR ë¡œë“œ ì‹œë„
    stt_model = AutoModelForSpeechSeq2Seq.from_pretrained(
        "microsoft/VibeVoice-ASR",
        quantization_config=quantization_config,
        device_map="auto",
        trust_remote_code=True,
    )
    stt_processor = AutoProcessor.from_pretrained(
        "microsoft/VibeVoice-ASR",
        trust_remote_code=True,
    )
    stt_pipe = pipeline(
        "automatic-speech-recognition",
        model=stt_model,
        tokenizer=stt_processor.tokenizer,
        feature_extractor=stt_processor.feature_extractor,
        device_map="auto",
    )
    STT_MODEL_NAME = "VibeVoice-ASR"
    print("âœ… VibeVoice-ASR loaded successfully!")
except Exception as e:
    print(f"âš ï¸ VibeVoice-ASR failed: {e}")
    print("Falling back to Whisper-large-v3...")

    # Fallback: Whisper-large-v3
    stt_model = AutoModelForSpeechSeq2Seq.from_pretrained(
        "openai/whisper-large-v3",
        torch_dtype=torch.float16,
        low_cpu_mem_usage=True,
        use_safetensors=True,
    )
    stt_model.to("cuda")
    stt_processor = AutoProcessor.from_pretrained("openai/whisper-large-v3")
    stt_pipe = pipeline(
        "automatic-speech-recognition",
        model=stt_model,
        tokenizer=stt_processor.tokenizer,
        feature_extractor=stt_processor.feature_extractor,
        torch_dtype=torch.float16,
        device="cuda",
    )
    STT_MODEL_NAME = "Whisper-large-v3"
    print("âœ… Whisper-large-v3 loaded successfully!")

# %% Cell 4: TTS ëª¨ë¸ ë¡œë“œ (Qwen3-TTS)
print("\nLoading Qwen3-TTS model...")

try:
    from qwen_tts import Qwen3TTSModel

    tts_model = Qwen3TTSModel.from_pretrained(
        "Qwen/Qwen3-TTS-12Hz-0.6B-Base",  # ê²½ëŸ‰ ë²„ì „ (0.6B)
        device_map="cuda:0",
        dtype=torch.float16,
    )
    TTS_MODEL_NAME = "Qwen3-TTS-0.6B"
    print("âœ… Qwen3-TTS loaded successfully!")
except Exception as e:
    print(f"âš ï¸ Qwen3-TTS failed: {e}")
    tts_model = None
    TTS_MODEL_NAME = "Not available"

# %% Cell 5: STT í•¨ìˆ˜ ì •ì˜
def transcribe(audio_path, language="korean"):
    """ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    if audio_path is None:
        return "ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."

    try:
        lang_map = {"korean": "ko", "english": "en", "japanese": "ja", "chinese": "zh"}
        lang_code = lang_map.get(language.lower(), "ko")

        result = stt_pipe(
            audio_path,
            generate_kwargs={"language": lang_code},
            return_timestamps=False,
        )

        return result["text"]
    except Exception as e:
        return f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# %% Cell 6: TTS í•¨ìˆ˜ ì •ì˜
def synthesize(text, language="Korean"):
    """í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜"""
    if not text or not text.strip():
        return None

    if tts_model is None:
        # Fallback: ë”ë¯¸ ì˜¤ë””ì˜¤ (ì‚¬ì¸íŒŒ)
        sample_rate = 24000
        duration = 1.0
        t = np.linspace(0, duration, int(sample_rate * duration))
        audio = np.sin(2 * np.pi * 440 * t) * 0.3

        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            sf.write(f.name, audio, sample_rate)
            return f.name

    try:
        wavs, sr = tts_model.generate_voice_clone(
            text=text,
            language=language,
            ref_audio=None,  # ê¸°ë³¸ ìŒì„± ì‚¬ìš©
        )

        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as f:
            sf.write(f.name, wavs[0], sr)
            return f.name
    except Exception as e:
        print(f"TTS error: {e}")
        return None

# %% Cell 7: Gradio UI ìƒì„±
with gr.Blocks(title="Pre-View ìŒì„± ì„œë¹„ìŠ¤") as demo:
    gr.Markdown(f"""
    # ğŸ™ï¸ Pre-View ìŒì„± ì„œë¹„ìŠ¤

    | ê¸°ëŠ¥ | ëª¨ë¸ |
    |------|------|
    | **STT** (ìŒì„±â†’í…ìŠ¤íŠ¸) | {STT_MODEL_NAME} |
    | **TTS** (í…ìŠ¤íŠ¸â†’ìŒì„±) | {TTS_MODEL_NAME} |
    """)

    with gr.Tab("ğŸ¤ STT (ìŒì„± ì¸ì‹)"):
        gr.Markdown("### ìŒì„± íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
        with gr.Row():
            with gr.Column():
                stt_audio = gr.Audio(type="filepath", label="ì˜¤ë””ì˜¤ íŒŒì¼")
                stt_language = gr.Dropdown(
                    choices=["korean", "english", "japanese", "chinese"],
                    value="korean",
                    label="ì–¸ì–´"
                )
                stt_btn = gr.Button("ë³€í™˜í•˜ê¸°", variant="primary")
            with gr.Column():
                stt_output = gr.Textbox(label="ë³€í™˜ ê²°ê³¼", lines=5)

        stt_btn.click(transcribe, inputs=[stt_audio, stt_language], outputs=stt_output)

    with gr.Tab("ğŸ”Š TTS (ìŒì„± í•©ì„±)"):
        gr.Markdown("### í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
        with gr.Row():
            with gr.Column():
                tts_text = gr.Textbox(
                    label="í…ìŠ¤íŠ¸",
                    placeholder="ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.",
                    lines=3
                )
                tts_language = gr.Dropdown(
                    choices=["Korean", "English", "Chinese", "Japanese"],
                    value="Korean",
                    label="ì–¸ì–´"
                )
                tts_btn = gr.Button("ìŒì„± ìƒì„±", variant="primary")
            with gr.Column():
                tts_output = gr.Audio(label="ìƒì„±ëœ ìŒì„±")

        tts_btn.click(synthesize, inputs=[tts_text, tts_language], outputs=tts_output)

# %% Cell 8: ì„œë¹„ìŠ¤ ì‹¤í–‰
print("\n" + "="*50)
print("ğŸš€ Starting Pre-View Voice Service...")
print("="*50)

demo.launch(share=True)  # share=Trueë¡œ ê³µê°œ URL ìƒì„±
